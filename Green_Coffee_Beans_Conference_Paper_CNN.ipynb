{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Green Coffee Beans Conference Paper_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_a2USyd4giE"
      },
      "source": [
        "# **Green Coffee Beans Conference Paper - Convolutional Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhzdomRTOKoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd27b985-151a-47c0-d876-7ee3308aebb3"
      },
      "source": [
        "# OpenCV 套件，和 Google Drive 無關\n",
        "import cv2\n",
        "# import Google Drive 套件\n",
        "from google.colab import drive\n",
        "# 將自己的雲端硬碟掛載上去\n",
        "drive.mount('/content/gdrive')\n",
        "#img = cv2.imread('gdrive/My Drive')\n",
        "#from google.colab.patches import cv2_imshow\n",
        "#cv2_imshow()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sVrKci4PUFW"
      },
      "source": [
        "# Import需要的套件\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import time\n",
        "import torchvision.models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0i9ZCPrOVN_"
      },
      "source": [
        "#Read image\n",
        "利用 OpenCV (cv2) 讀入照片並存放在 numpy array 中"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf7QPifJQNUK"
      },
      "source": [
        "def readfile(path):\n",
        "    good_path = path + \"/good\"\n",
        "    bad_path = path + \"/bad\"\n",
        "    good_image_dir = sorted(os.listdir(good_path))\n",
        "    bad_image_dir = sorted(os.listdir(bad_path))\n",
        "    x = np.zeros((len(good_image_dir + bad_image_dir), 256, 256, 3), dtype=np.uint8)\n",
        "    y = np.zeros((len(good_image_dir + bad_image_dir)), dtype=np.uint8)\n",
        "    for i, file in enumerate(good_image_dir):\n",
        "        good_img = cv2.imread(os.path.join(good_path, file))\n",
        "        x[i, :, :] = cv2.resize(good_img,(256, 256))\n",
        "        y[i] = 1\n",
        "    for i, file in enumerate(bad_image_dir):\n",
        "        bad_img = cv2.imread(os.path.join(bad_path, file))\n",
        "        x[i, :, :] = cv2.resize(bad_img,(256, 256))\n",
        "        y[i + len(good_image_dir)] = 0\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZr0bg-riI09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "562692eb-e9f2-4946-edbd-8f46ba40fe5f"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ebVIY5HQQH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6317d6f-28fe-4471-b107-6e667183a06d"
      },
      "source": [
        "# 分別將 training set、validation set、testing set 用 readfile 函式讀進來\n",
        "workspace_dir = 'gdrive/My Drive/dataset/'\n",
        "print(\"Reading data\")\n",
        "train_x, train_y = readfile(os.path.join(workspace_dir, \"training2\"))\n",
        "print(\"Size of training data = {}\".format(len(train_x)))\n",
        "val_x, val_y = readfile(os.path.join(workspace_dir, \"validation2\"))\n",
        "print(\"Size of validation data = {}\".format(len(val_x)))\n",
        "test_x, test_y = readfile(os.path.join(workspace_dir, \"testing2\"))\n",
        "print(\"Size of Testing data = {}\".format(len(test_x)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading data\n",
            "Size of training data = 3691\n",
            "Size of validation data = 463\n",
            "Size of Testing data = 463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq5KVMM3OHY6"
      },
      "source": [
        "# Dataset\n",
        "在 PyTorch 中，我們可以利用 torch.utils.data 的 Dataset 及 DataLoader 來\"包裝\" data，使後續的 training 及 testing 更為方便。\n",
        "\n",
        "Dataset 需要 overload 兩個函數：\\_\\_len\\_\\_ 及 \\_\\_getitem\\_\\_\n",
        "\n",
        "\\_\\_len\\_\\_ 必須要回傳 dataset 的大小，而 \\_\\_getitem\\_\\_ 則定義了當程式利用 [ ] 取值時，dataset 應該要怎麼回傳資料。\n",
        "\n",
        "實際上我們並不會直接使用到這兩個函數，但是使用 DataLoader 在 enumerate Dataset 時會使用到，沒有實做的話會在程式運行階段出現 error。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKd2abixQghI"
      },
      "source": [
        "# training 時做 data augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(), # 隨機將圖片水平翻轉\n",
        "    transforms.RandomRotation(15), # 隨機旋轉圖片\n",
        "    transforms.ToTensor(), # 將圖片轉成 Tensor，並把數值 normalize 到 [0,1] (data normalization)\n",
        "])\n",
        "# testing 時不需做 data augmentation\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),                                    \n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "class ImgDataset(Dataset):\n",
        "    def __init__(self, x, y=None, transform=None):\n",
        "        self.x = x\n",
        "        # label is required to be a LongTensor\n",
        "        self.y = y\n",
        "        if y is not None:\n",
        "            self.y = torch.LongTensor(y)\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    def __getitem__(self, index):\n",
        "        X = self.x[index]\n",
        "        if self.transform is not None:\n",
        "            X = self.transform(X)\n",
        "        if self.y is not None:\n",
        "            Y = self.y[index]\n",
        "            return X, Y\n",
        "        else:\n",
        "            return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz6jeMnkQl0_"
      },
      "source": [
        "batch_size = 8 #32以內\n",
        "train_set = ImgDataset(train_x, train_y, train_transform)\n",
        "val_set = ImgDataset(val_x, val_y, test_transform)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9YhZo7POPYG"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1c-GwrMQqMl"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
        "        # input 維度 [3, 128, 128]\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n",
        "\n",
        "            nn.Conv2d(256, 128, 3, 1, 1), # [512, 16, 16]\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
        "            \n",
        "            nn.Conv2d(128, 128, 3, 1, 1), # [512, 8, 8]\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128*8*8, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return self.fc(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JElg3C66nGVG",
        "outputId": "8e758cf1-faeb-4f93-af65-5c39baa69f62"
      },
      "source": [
        "!pip install thop\n",
        "import torch\n",
        "import torchvision\n",
        "import time\n",
        "from thop import profile\n",
        "# 增加可读性\n",
        "from thop import clever_format\n",
        "\n",
        "# 可替换为自己的模型及输入\n",
        "start = time.time()\n",
        "model = torchvision.models.vgg16(pretrained=False, progress=True, num_classes = 2)\n",
        "input = torch.randn(1, 3, 224, 224)\n",
        "flops, params = profile(model, inputs=(input, ))\n",
        "flops, params = clever_format([flops, params], \"%.3f\")\n",
        "end = time.time()\n",
        "print(flops, params)\n",
        "print(end-start)\n",
        "\n",
        "# 可替换为自己的模型及输入\n",
        "start = time.time()\n",
        "model = torchvision.models.resnet50(pretrained=False, progress=True, num_classes = 2)\n",
        "input = torch.randn(1, 3, 224, 224)\n",
        "flops, params = profile(model, inputs=(input, ))\n",
        "flops, params = clever_format([flops, params], \"%.3f\")\n",
        "end = time.time()\n",
        "print(flops, params)\n",
        "print(end-start)\n",
        "\n",
        "# 可替换为自己的模型及输入\n",
        "start = time.time()\n",
        "model = torchvision.models.densenet121(pretrained=False, progress=True, num_classes = 2)\n",
        "input = torch.randn(1, 3, 224, 224)\n",
        "flops, params = profile(model, inputs=(input, ))\n",
        "flops, params = clever_format([flops, params], \"%.3f\")\n",
        "end = time.time()\n",
        "print(flops, params)\n",
        "print(end-start)\n",
        "\n",
        "# 可替换为自己的模型及输入\n",
        "start = time.time()\n",
        "model = torchvision.models.mobilenet_v2(pretrained=False, progress=True, num_classes = 2)\n",
        "input = torch.randn(1, 3, 224, 224)\n",
        "flops, params = profile(model, inputs=(input, ))\n",
        "flops, params = clever_format([flops, params], \"%.3f\")\n",
        "end = time.time()\n",
        "print(flops, params)\n",
        "print(end-start)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.6/dist-packages (0.0.31.post2005241907)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from thop) (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (3.7.4.3)\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.vgg.VGG'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "15.480G 134.269M\n",
            "2.540384531021118\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.resnet.Bottleneck'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.resnet.ResNet'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "4.109G 23.512M\n",
            "0.5776739120483398\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.densenet._DenseLayer'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.densenet._DenseBlock'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.densenet._Transition'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.densenet.DenseNet'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "2.865G 6.956M\n",
            "0.3623921871185303\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU6'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.mobilenet.ConvBNReLU'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.mobilenet.InvertedResidual'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.mobilenet.MobileNetV2'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "312.853M 2.226M\n",
            "0.1268315315246582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWP7yorf1yUz"
      },
      "source": [
        "vgg16 = torchvision.models.vgg16(pretrained=False, progress=True, num_classes = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CENWTZNaSwMJ"
      },
      "source": [
        "resNet18 = torchvision.models.resnet18(pretrained=False, progress=True, num_classes = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwV9moVYbQ5V"
      },
      "source": [
        "resNet50 = torchvision.models.resnet50(pretrained=False, progress=True, num_classes = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLk0W7kXem3j"
      },
      "source": [
        "denseNet121 = torchvision.models.densenet121(pretrained=False, progress=True, num_classes = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWSz2nLJHQIB"
      },
      "source": [
        "mobilenet = torchvision.models.mobilenet_v2(pretrained=False, progress=True, num_classes = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbethJ5rHQo0",
        "outputId": "a08be07a-4084-490e-f7ee-ff62f0796537"
      },
      "source": [
        "!pip install pretrainedmodels\n",
        "import pretrainedmodels\n",
        "model_name = 'xception'\n",
        "xception = pretrainedmodels.__dict__[model_name](num_classes = 2, pretrained = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pretrainedmodels in /usr/local/lib/python3.6/dist-packages (0.7.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.41.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.8.1+cu101)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.7.0+cu101)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (2.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (7.0.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch->pretrainedmodels) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhTIwCpf_4D0",
        "outputId": "3bce46dc-2d6e-47bc-99c5-4745c137a2a0"
      },
      "source": [
        "!pip install thop\n",
        "import torch\n",
        "import torchvision\n",
        "import time\n",
        "from thop import profile\n",
        "# 增加可读性\n",
        "from thop import clever_format\n",
        "# 可替换为自己的模型及输入\n",
        "start = time.time()\n",
        "model = xception\n",
        "input = torch.randn(1, 3, 224, 224)\n",
        "flops, params = profile(model, inputs=(input, ))\n",
        "flops, params = clever_format([flops, params], \"%.3f\")\n",
        "end = time.time()\n",
        "print(flops, params)\n",
        "print(end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.6/dist-packages (0.0.31.post2005241907)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from thop) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->thop) (0.8)\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'pretrainedmodels.models.xception.SeparableConv2d'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'pretrainedmodels.models.xception.Block'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'pretrainedmodels.models.xception.Xception'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "4.574G 20.811M\n",
            "0.24268007278442383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXouch00qcCG"
      },
      "source": [
        "!apt install psmisc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEnGbriXORN3"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5x-FH2Kr_jh"
      },
      "source": [
        "使用 training set 訓練，並使用 validation set 尋找好的參數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHaFE-8oQtkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ced9a5-22ef-4281-b252-a5d9b45b908a"
      },
      "source": [
        "#model = Classifier().cuda()\n",
        "model = vgg16.cuda()\n",
        "#model = resNet18.cuda()\n",
        "#model = resNet101.cuda()\n",
        "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) # optimizer 使用 Adam\n",
        "num_epoch = 50\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
        "        train_pred = model(data[0].cuda()) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
        "        batch_loss = loss(train_pred, data[1].cuda()) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
        "        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
        "        optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
        "\n",
        "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "        train_loss += batch_loss.item()\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "            val_pred = model(data[0].cuda())\n",
        "            batch_loss = loss(val_pred, data[1].cuda())\n",
        "\n",
        "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "            val_loss += batch_loss.item()\n",
        "            '''\n",
        "            if((epoch+1) % 10 == 0):\n",
        "              torch.save(model.state_dict(), 'gdrive/My Drive/dataset/teacher_model_resNet101.bin')\n",
        "            '''\n",
        "\n",
        "        #將結果 print 出來\n",
        "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
        "            (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
        "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[001/100] 140.57 sec(s) Train Acc: 0.926307 Loss: 0.032252 | Val Acc: 0.928726 loss: 0.026785\n",
            "[002/100] 141.25 sec(s) Train Acc: 0.929829 Loss: 0.029289 | Val Acc: 0.928726 loss: 0.027186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-ssSxXlsI_T"
      },
      "source": [
        "得到好的參數後，我們使用 training set 和 validation set 共同訓練（資料量變多，模型效果較好）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKoUxLun8lFG"
      },
      "source": [
        "train_val_x = np.concatenate((train_x, val_x), axis=0)\n",
        "train_val_y = np.concatenate((train_y, val_y), axis=0)\n",
        "train_val_set = ImgDataset(train_val_x, train_val_y, train_transform)\n",
        "train_val_loader = DataLoader(train_val_set, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoAS5TtRsfOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d08cd3-0d74-4e92-af7b-0f537af98339"
      },
      "source": [
        "#model_best = Classifier().cuda()\n",
        "#model_best = vgg16.cuda()\n",
        "model_best = resNet18.cuda()\n",
        "#model_best = resNet50.cuda()\n",
        "#model_best = denseNet121.cuda()\n",
        "#model_best = mobilenet.cuda()\n",
        "#model_best = xception.cuda()\n",
        "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
        "optimizer = torch.optim.Adam(model_best.parameters(), lr=0.0001) # optimizer 使用 Adam\n",
        "num_epoch = 200\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    epoch_start_time = time.time()\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "\n",
        "    model_best.train()\n",
        "    for i, data in enumerate(train_val_loader):\n",
        "        optimizer.zero_grad()\n",
        "        train_pred = model_best(data[0].cuda())\n",
        "        batch_loss = loss(train_pred, data[1].cuda())\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
        "        train_loss += batch_loss.item()\n",
        "        if((epoch+1) % 10 == 0):\n",
        "          torch.save(model_best.state_dict(), 'gdrive/My Drive/dataset/teacher_model_resNet18.bin')\n",
        "\n",
        "        #將結果 print 出來\n",
        "    print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f' % \\\n",
        "      (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
        "      train_acc/train_val_set.__len__(), train_loss/train_val_set.__len__()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[001/200] 70.07 sec(s) Train Acc: 0.941502 Loss: 0.018232\n",
            "[002/200] 70.41 sec(s) Train Acc: 0.935243 Loss: 0.019876\n",
            "[003/200] 69.66 sec(s) Train Acc: 0.941743 Loss: 0.018213\n",
            "[004/200] 69.74 sec(s) Train Acc: 0.943909 Loss: 0.018192\n",
            "[005/200] 69.79 sec(s) Train Acc: 0.946076 Loss: 0.016961\n",
            "[006/200] 69.65 sec(s) Train Acc: 0.946798 Loss: 0.017920\n",
            "[007/200] 69.66 sec(s) Train Acc: 0.949206 Loss: 0.016227\n",
            "[008/200] 69.78 sec(s) Train Acc: 0.948965 Loss: 0.016555\n",
            "[009/200] 69.70 sec(s) Train Acc: 0.951131 Loss: 0.015590\n",
            "[010/200] 570.08 sec(s) Train Acc: 0.950891 Loss: 0.015499\n",
            "[011/200] 69.93 sec(s) Train Acc: 0.953779 Loss: 0.014702\n",
            "[012/200] 69.84 sec(s) Train Acc: 0.954502 Loss: 0.015582\n",
            "[013/200] 69.94 sec(s) Train Acc: 0.954742 Loss: 0.014700\n",
            "[014/200] 69.92 sec(s) Train Acc: 0.956428 Loss: 0.013744\n",
            "[015/200] 69.79 sec(s) Train Acc: 0.957631 Loss: 0.014159\n",
            "[016/200] 69.83 sec(s) Train Acc: 0.958353 Loss: 0.013423\n",
            "[017/200] 69.88 sec(s) Train Acc: 0.957872 Loss: 0.013833\n",
            "[018/200] 69.77 sec(s) Train Acc: 0.957150 Loss: 0.013198\n",
            "[019/200] 69.89 sec(s) Train Acc: 0.960279 Loss: 0.013211\n",
            "[020/200] 561.90 sec(s) Train Acc: 0.956668 Loss: 0.013599\n",
            "[021/200] 69.77 sec(s) Train Acc: 0.959798 Loss: 0.012819\n",
            "[022/200] 69.95 sec(s) Train Acc: 0.963409 Loss: 0.012440\n",
            "[023/200] 69.91 sec(s) Train Acc: 0.966298 Loss: 0.011696\n",
            "[024/200] 69.89 sec(s) Train Acc: 0.962205 Loss: 0.011900\n",
            "[025/200] 69.90 sec(s) Train Acc: 0.962927 Loss: 0.011555\n",
            "[026/200] 69.95 sec(s) Train Acc: 0.964372 Loss: 0.011774\n",
            "[027/200] 69.77 sec(s) Train Acc: 0.967020 Loss: 0.011778\n",
            "[028/200] 69.88 sec(s) Train Acc: 0.966779 Loss: 0.011438\n",
            "[029/200] 69.79 sec(s) Train Acc: 0.962687 Loss: 0.010862\n",
            "[030/200] 560.20 sec(s) Train Acc: 0.963649 Loss: 0.011393\n",
            "[031/200] 69.98 sec(s) Train Acc: 0.967742 Loss: 0.010808\n",
            "[032/200] 69.85 sec(s) Train Acc: 0.970631 Loss: 0.010690\n",
            "[033/200] 69.86 sec(s) Train Acc: 0.970390 Loss: 0.010383\n",
            "[034/200] 69.87 sec(s) Train Acc: 0.971353 Loss: 0.009622\n",
            "[035/200] 69.94 sec(s) Train Acc: 0.970631 Loss: 0.009938\n",
            "[036/200] 69.90 sec(s) Train Acc: 0.971834 Loss: 0.009887\n",
            "[037/200] 69.95 sec(s) Train Acc: 0.970631 Loss: 0.009497\n",
            "[038/200] 69.86 sec(s) Train Acc: 0.972797 Loss: 0.009616\n",
            "[039/200] 69.90 sec(s) Train Acc: 0.973760 Loss: 0.009033\n",
            "[040/200] 562.94 sec(s) Train Acc: 0.969668 Loss: 0.009550\n",
            "[041/200] 69.92 sec(s) Train Acc: 0.973038 Loss: 0.008814\n",
            "[042/200] 69.94 sec(s) Train Acc: 0.973760 Loss: 0.009023\n",
            "[043/200] 69.92 sec(s) Train Acc: 0.976890 Loss: 0.008091\n",
            "[044/200] 69.91 sec(s) Train Acc: 0.971834 Loss: 0.008817\n",
            "[045/200] 69.89 sec(s) Train Acc: 0.974242 Loss: 0.008529\n",
            "[046/200] 69.88 sec(s) Train Acc: 0.971594 Loss: 0.009710\n",
            "[047/200] 69.85 sec(s) Train Acc: 0.972557 Loss: 0.008523\n",
            "[048/200] 69.91 sec(s) Train Acc: 0.976649 Loss: 0.008113\n",
            "[049/200] 69.93 sec(s) Train Acc: 0.977371 Loss: 0.007854\n",
            "[050/200] 561.64 sec(s) Train Acc: 0.979779 Loss: 0.008033\n",
            "[051/200] 69.86 sec(s) Train Acc: 0.977130 Loss: 0.007428\n",
            "[052/200] 69.83 sec(s) Train Acc: 0.974482 Loss: 0.007906\n",
            "[053/200] 69.92 sec(s) Train Acc: 0.973279 Loss: 0.008629\n",
            "[054/200] 69.78 sec(s) Train Acc: 0.979538 Loss: 0.007211\n",
            "[055/200] 69.88 sec(s) Train Acc: 0.975927 Loss: 0.008138\n",
            "[056/200] 69.91 sec(s) Train Acc: 0.981704 Loss: 0.006758\n",
            "[057/200] 69.88 sec(s) Train Acc: 0.972557 Loss: 0.008516\n",
            "[058/200] 69.94 sec(s) Train Acc: 0.979779 Loss: 0.006900\n",
            "[059/200] 69.93 sec(s) Train Acc: 0.980019 Loss: 0.006798\n",
            "[060/200] 559.72 sec(s) Train Acc: 0.978816 Loss: 0.007178\n",
            "[061/200] 69.79 sec(s) Train Acc: 0.980982 Loss: 0.006680\n",
            "[062/200] 69.70 sec(s) Train Acc: 0.976168 Loss: 0.006919\n",
            "[063/200] 69.81 sec(s) Train Acc: 0.978575 Loss: 0.006878\n",
            "[064/200] 69.76 sec(s) Train Acc: 0.979779 Loss: 0.006669\n",
            "[065/200] 69.80 sec(s) Train Acc: 0.980019 Loss: 0.007002\n",
            "[066/200] 69.81 sec(s) Train Acc: 0.977853 Loss: 0.006953\n",
            "[067/200] 69.86 sec(s) Train Acc: 0.982908 Loss: 0.006476\n",
            "[068/200] 69.83 sec(s) Train Acc: 0.978575 Loss: 0.006695\n",
            "[069/200] 69.80 sec(s) Train Acc: 0.979779 Loss: 0.006235\n",
            "[070/200] 562.18 sec(s) Train Acc: 0.984352 Loss: 0.005843\n",
            "[071/200] 69.77 sec(s) Train Acc: 0.985315 Loss: 0.005360\n",
            "[072/200] 69.78 sec(s) Train Acc: 0.981223 Loss: 0.006246\n",
            "[073/200] 69.88 sec(s) Train Acc: 0.985075 Loss: 0.005594\n",
            "[074/200] 69.79 sec(s) Train Acc: 0.981704 Loss: 0.006318\n",
            "[075/200] 69.80 sec(s) Train Acc: 0.984834 Loss: 0.005701\n",
            "[076/200] 69.79 sec(s) Train Acc: 0.983390 Loss: 0.005742\n",
            "[077/200] 69.84 sec(s) Train Acc: 0.983871 Loss: 0.005829\n",
            "[078/200] 69.80 sec(s) Train Acc: 0.983149 Loss: 0.005475\n",
            "[079/200] 69.72 sec(s) Train Acc: 0.979297 Loss: 0.006109\n",
            "[080/200] 563.07 sec(s) Train Acc: 0.984352 Loss: 0.005054\n",
            "[081/200] 69.79 sec(s) Train Acc: 0.982667 Loss: 0.005937\n",
            "[082/200] 69.81 sec(s) Train Acc: 0.984593 Loss: 0.004984\n",
            "[083/200] 69.79 sec(s) Train Acc: 0.982427 Loss: 0.005450\n",
            "[084/200] 69.82 sec(s) Train Acc: 0.987000 Loss: 0.004740\n",
            "[085/200] 69.83 sec(s) Train Acc: 0.984352 Loss: 0.005168\n",
            "[086/200] 69.85 sec(s) Train Acc: 0.982186 Loss: 0.005416\n",
            "[087/200] 69.93 sec(s) Train Acc: 0.986760 Loss: 0.004673\n",
            "[088/200] 69.88 sec(s) Train Acc: 0.984593 Loss: 0.005020\n",
            "[089/200] 69.84 sec(s) Train Acc: 0.987723 Loss: 0.004456\n",
            "[090/200] 558.94 sec(s) Train Acc: 0.984112 Loss: 0.005445\n",
            "[091/200] 69.86 sec(s) Train Acc: 0.987000 Loss: 0.004396\n",
            "[092/200] 69.98 sec(s) Train Acc: 0.985797 Loss: 0.004978\n",
            "[093/200] 69.96 sec(s) Train Acc: 0.985556 Loss: 0.005418\n",
            "[094/200] 69.82 sec(s) Train Acc: 0.985075 Loss: 0.004883\n",
            "[095/200] 69.85 sec(s) Train Acc: 0.985556 Loss: 0.004532\n",
            "[096/200] 69.91 sec(s) Train Acc: 0.987723 Loss: 0.004535\n",
            "[097/200] 69.97 sec(s) Train Acc: 0.986278 Loss: 0.004590\n",
            "[098/200] 69.89 sec(s) Train Acc: 0.985075 Loss: 0.004688\n",
            "[099/200] 69.89 sec(s) Train Acc: 0.987723 Loss: 0.004185\n",
            "[100/200] 563.29 sec(s) Train Acc: 0.986760 Loss: 0.004510\n",
            "[101/200] 69.67 sec(s) Train Acc: 0.987963 Loss: 0.004504\n",
            "[102/200] 69.81 sec(s) Train Acc: 0.984112 Loss: 0.005315\n",
            "[103/200] 69.71 sec(s) Train Acc: 0.986278 Loss: 0.004427\n",
            "[104/200] 69.88 sec(s) Train Acc: 0.986278 Loss: 0.004656\n",
            "[105/200] 69.95 sec(s) Train Acc: 0.985556 Loss: 0.004183\n",
            "[106/200] 69.71 sec(s) Train Acc: 0.986278 Loss: 0.003967\n",
            "[107/200] 69.86 sec(s) Train Acc: 0.986760 Loss: 0.004787\n",
            "[108/200] 69.87 sec(s) Train Acc: 0.989408 Loss: 0.004397\n",
            "[109/200] 69.84 sec(s) Train Acc: 0.988445 Loss: 0.004365\n",
            "[110/200] 562.16 sec(s) Train Acc: 0.984593 Loss: 0.004182\n",
            "[111/200] 69.81 sec(s) Train Acc: 0.987963 Loss: 0.004029\n",
            "[112/200] 69.90 sec(s) Train Acc: 0.988686 Loss: 0.003657\n",
            "[113/200] 69.82 sec(s) Train Acc: 0.989889 Loss: 0.003948\n",
            "[114/200] 69.88 sec(s) Train Acc: 0.987723 Loss: 0.004168\n",
            "[115/200] 69.92 sec(s) Train Acc: 0.989167 Loss: 0.003737\n",
            "[116/200] 69.79 sec(s) Train Acc: 0.987241 Loss: 0.004320\n",
            "[117/200] 69.89 sec(s) Train Acc: 0.989167 Loss: 0.005352\n",
            "[118/200] 69.88 sec(s) Train Acc: 0.988204 Loss: 0.004447\n",
            "[119/200] 69.90 sec(s) Train Acc: 0.989649 Loss: 0.003535\n",
            "[120/200] 559.92 sec(s) Train Acc: 0.989408 Loss: 0.003543\n",
            "[121/200] 69.82 sec(s) Train Acc: 0.990852 Loss: 0.003416\n",
            "[122/200] 69.82 sec(s) Train Acc: 0.988445 Loss: 0.004194\n",
            "[123/200] 69.82 sec(s) Train Acc: 0.988686 Loss: 0.003566\n",
            "[124/200] 69.83 sec(s) Train Acc: 0.986760 Loss: 0.003917\n",
            "[125/200] 69.73 sec(s) Train Acc: 0.988204 Loss: 0.003897\n",
            "[126/200] 69.73 sec(s) Train Acc: 0.989649 Loss: 0.003500\n",
            "[127/200] 69.81 sec(s) Train Acc: 0.987482 Loss: 0.004021\n",
            "[128/200] 69.81 sec(s) Train Acc: 0.989889 Loss: 0.003556\n",
            "[129/200] 69.71 sec(s) Train Acc: 0.989408 Loss: 0.003322\n",
            "[130/200] 560.73 sec(s) Train Acc: 0.991574 Loss: 0.002740\n",
            "[131/200] 70.48 sec(s) Train Acc: 0.989167 Loss: 0.003397\n",
            "[132/200] 70.60 sec(s) Train Acc: 0.987723 Loss: 0.003743\n",
            "[133/200] 70.64 sec(s) Train Acc: 0.990611 Loss: 0.002847\n",
            "[134/200] 70.61 sec(s) Train Acc: 0.992778 Loss: 0.002489\n",
            "[135/200] 70.59 sec(s) Train Acc: 0.988926 Loss: 0.003704\n",
            "[136/200] 70.49 sec(s) Train Acc: 0.989408 Loss: 0.003593\n",
            "[137/200] 70.49 sec(s) Train Acc: 0.990371 Loss: 0.003051\n",
            "[138/200] 70.47 sec(s) Train Acc: 0.988926 Loss: 0.003304\n",
            "[139/200] 70.59 sec(s) Train Acc: 0.987963 Loss: 0.003674\n",
            "[140/200] 561.41 sec(s) Train Acc: 0.989408 Loss: 0.003630\n",
            "[141/200] 70.56 sec(s) Train Acc: 0.989889 Loss: 0.002949\n",
            "[142/200] 70.63 sec(s) Train Acc: 0.989889 Loss: 0.003334\n",
            "[143/200] 70.60 sec(s) Train Acc: 0.990852 Loss: 0.003350\n",
            "[144/200] 70.58 sec(s) Train Acc: 0.991093 Loss: 0.003200\n",
            "[145/200] 70.59 sec(s) Train Acc: 0.991334 Loss: 0.003020\n",
            "[146/200] 70.59 sec(s) Train Acc: 0.990852 Loss: 0.002950\n",
            "[147/200] 70.57 sec(s) Train Acc: 0.989889 Loss: 0.003732\n",
            "[148/200] 70.62 sec(s) Train Acc: 0.989408 Loss: 0.003307\n",
            "[149/200] 70.58 sec(s) Train Acc: 0.991093 Loss: 0.003377\n",
            "[150/200] 562.83 sec(s) Train Acc: 0.989649 Loss: 0.003803\n",
            "[151/200] 70.74 sec(s) Train Acc: 0.991574 Loss: 0.002684\n",
            "[152/200] 70.76 sec(s) Train Acc: 0.991574 Loss: 0.002505\n",
            "[153/200] 70.80 sec(s) Train Acc: 0.990611 Loss: 0.003455\n",
            "[154/200] 70.67 sec(s) Train Acc: 0.989408 Loss: 0.003159\n",
            "[155/200] 70.77 sec(s) Train Acc: 0.991574 Loss: 0.002663\n",
            "[156/200] 70.68 sec(s) Train Acc: 0.991574 Loss: 0.002815\n",
            "[157/200] 70.60 sec(s) Train Acc: 0.989408 Loss: 0.003295\n",
            "[158/200] 70.65 sec(s) Train Acc: 0.990611 Loss: 0.002879\n",
            "[159/200] 70.70 sec(s) Train Acc: 0.989408 Loss: 0.003836\n",
            "[160/200] 562.16 sec(s) Train Acc: 0.992778 Loss: 0.002584\n",
            "[161/200] 70.54 sec(s) Train Acc: 0.990371 Loss: 0.003176\n",
            "[162/200] 70.63 sec(s) Train Acc: 0.991093 Loss: 0.002966\n",
            "[163/200] 70.66 sec(s) Train Acc: 0.990611 Loss: 0.002784\n",
            "[164/200] 70.69 sec(s) Train Acc: 0.990852 Loss: 0.003446\n",
            "[165/200] 70.67 sec(s) Train Acc: 0.992537 Loss: 0.002544\n",
            "[166/200] 70.65 sec(s) Train Acc: 0.990611 Loss: 0.002438\n",
            "[167/200] 70.70 sec(s) Train Acc: 0.989649 Loss: 0.003342\n",
            "[168/200] 70.58 sec(s) Train Acc: 0.990611 Loss: 0.002554\n",
            "[169/200] 70.53 sec(s) Train Acc: 0.994463 Loss: 0.002369\n",
            "[170/200] 559.88 sec(s) Train Acc: 0.991093 Loss: 0.002879\n",
            "[171/200] 70.53 sec(s) Train Acc: 0.991093 Loss: 0.002628\n",
            "[172/200] 70.70 sec(s) Train Acc: 0.993019 Loss: 0.002598\n",
            "[173/200] 70.78 sec(s) Train Acc: 0.988686 Loss: 0.003249\n",
            "[174/200] 70.64 sec(s) Train Acc: 0.993260 Loss: 0.001980\n",
            "[175/200] 70.67 sec(s) Train Acc: 0.992537 Loss: 0.002307\n",
            "[176/200] 70.76 sec(s) Train Acc: 0.992297 Loss: 0.002423\n",
            "[177/200] 70.78 sec(s) Train Acc: 0.991334 Loss: 0.002780\n",
            "[178/200] 70.67 sec(s) Train Acc: 0.990852 Loss: 0.002870\n",
            "[179/200] 70.86 sec(s) Train Acc: 0.992778 Loss: 0.002733\n",
            "[180/200] 562.25 sec(s) Train Acc: 0.992056 Loss: 0.002114\n",
            "[181/200] 70.32 sec(s) Train Acc: 0.991574 Loss: 0.002832\n",
            "[182/200] 70.37 sec(s) Train Acc: 0.993260 Loss: 0.002288\n",
            "[183/200] 70.43 sec(s) Train Acc: 0.993260 Loss: 0.002353\n",
            "[184/200] 70.36 sec(s) Train Acc: 0.992778 Loss: 0.002436\n",
            "[185/200] 70.39 sec(s) Train Acc: 0.989408 Loss: 0.002678\n",
            "[186/200] 70.39 sec(s) Train Acc: 0.993741 Loss: 0.002415\n",
            "[187/200] 70.35 sec(s) Train Acc: 0.993260 Loss: 0.002005\n",
            "[188/200] 70.38 sec(s) Train Acc: 0.990371 Loss: 0.002984\n",
            "[189/200] 70.34 sec(s) Train Acc: 0.990611 Loss: 0.002860\n",
            "[190/200] 561.75 sec(s) Train Acc: 0.991815 Loss: 0.002658\n",
            "[191/200] 70.27 sec(s) Train Acc: 0.994222 Loss: 0.001865\n",
            "[192/200] 70.42 sec(s) Train Acc: 0.992537 Loss: 0.002649\n",
            "[193/200] 70.33 sec(s) Train Acc: 0.994945 Loss: 0.001855\n",
            "[194/200] 70.43 sec(s) Train Acc: 0.992778 Loss: 0.002135\n",
            "[195/200] 70.38 sec(s) Train Acc: 0.990371 Loss: 0.003030\n",
            "[196/200] 70.36 sec(s) Train Acc: 0.994704 Loss: 0.001656\n",
            "[197/200] 70.39 sec(s) Train Acc: 0.990371 Loss: 0.002866\n",
            "[198/200] 70.45 sec(s) Train Acc: 0.992778 Loss: 0.002034\n",
            "[199/200] 70.34 sec(s) Train Acc: 0.992537 Loss: 0.002296\n",
            "[200/200] 562.61 sec(s) Train Acc: 0.993982 Loss: 0.001738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o1oCMXy61_3"
      },
      "source": [
        "# Testing\n",
        "利用剛剛 train 好的 model 進行 prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAR6sn8U661G"
      },
      "source": [
        "test_set = ImgDataset(test_x, transform=test_transform)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HznI9_-ocrq"
      },
      "source": [
        "model_best.eval()\n",
        "prediction = []\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        test_pred = model_best(data.cuda())\n",
        "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
        "        for y in test_label:\n",
        "            prediction.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1X3tNHn_A7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "858a9aa2-1758-435a-9fb7-2b64da028dae"
      },
      "source": [
        "from sklearn import metrics\n",
        "target_names=[\"labels_0\"]\n",
        "for i in range(1,2):\n",
        "    target_names.append('labels_'+str(i))\n",
        "print(\"classification report:\")\n",
        "print(metrics.classification_report(prediction,val_y,target_names=target_names,digits=4))\n",
        "print(\"Accuracy: \"+str(format(metrics.accuracy_score(prediction,val_y),'0.4f')))\n",
        "print(\"Confusion Matrix:\")\n",
        "print (metrics.confusion_matrix(prediction,val_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    labels_0     0.8871    0.9167    0.9016       240\n",
            "    labels_1     0.9070    0.8744    0.8904       223\n",
            "\n",
            "    accuracy                         0.8963       463\n",
            "   macro avg     0.8970    0.8956    0.8960       463\n",
            "weighted avg     0.8967    0.8963    0.8962       463\n",
            "\n",
            "Accuracy: 0.8963\n",
            "Confusion Matrix:\n",
            "[[220  20]\n",
            " [ 28 195]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t2q2Th85ZUE"
      },
      "source": [
        "#將結果寫入 csv 檔\n",
        "with open(\"gdrive/My Drive/predict.csv\", 'w') as f:\n",
        "    f.write('Id,Category\\n')\n",
        "    for i, y in  enumerate(prediction):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}